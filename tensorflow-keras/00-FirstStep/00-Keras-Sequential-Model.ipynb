{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When to Use Sequnetial Model\n",
    "- Keras has two types of models Sequential and API.\n",
    "- Sequential model is a stack of plain layers\n",
    "- If there is no need of connecting one layer with multiple layers sequential model is the best one\n",
    "- A Sequential model is appropriate for a plain stack of layers where each layer has exactly one input tensor and one output tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a sequential model with 3 layers\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "    keras.layers.Dense(2, activation=\"relu\", name=\"layer1\"),\n",
    "    keras.layers.Dense(3, activation=\"relu\", name=\"layer2\"),\n",
    "    keras.layers.Dense(4, name=\"layer3\")\n",
    "    ])\n",
    "# Call model on a test input\n",
    "x = tf.ones([3,3])\n",
    "y = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which is equivalent to following code\n",
    "layer1 = keras.layers.Dense(2, activation=\"relu\", name=\"layer1\")\n",
    "layer2 = keras.layers.Dense(3, activation=\"relu\", name=\"layer2\")\n",
    "layer3 = keras.layers.Dense(4, name=\"layer3\")\n",
    "\n",
    "# lets test this model again\n",
    "x = tf.ones([3,3])\n",
    "y = layer3(layer2(layer1(x)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A sequential Model is not appropriate when\n",
    "- when a layers should connect to multiple inputs or multiple outputs\n",
    "- Overall model has multiple inputs or multiple outputs\n",
    "- When there is a need of layers sharing\n",
    "- When we want to develop a non-linear topology (e.g., a residula connection, a multi-branch model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.core.dense.Dense at 0x1d0442c7f70>,\n",
       " <keras.layers.core.dense.Dense at 0x1d044338af0>,\n",
       " <keras.layers.core.dense.Dense at 0x1d044338d30>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can create a Sequential model by passing a list of layers to the Sequential constructor:\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(2, activation=\"relu\"),\n",
    "        keras.layers.Dense(3, activation=\"relu\"),\n",
    "        keras.layers.Dense(4),\n",
    "    ]\n",
    ")\n",
    "# Its layers are accessible via the layers attribute:\n",
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# You can also create a Sequential model incrementally via the add() method:\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(2, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(3, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(4))\n",
    "\n",
    "# Note that there's also a corresponding pop() method to remove layers: \n",
    "# a Sequential model behaves very much like a list of layers.\n",
    "model.pop()\n",
    "print(len(model.layers))  # 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.core.dense.Dense at 0x1d0443b9700>,\n",
       " <keras.layers.core.dense.Dense at 0x1d041565250>,\n",
       " <keras.layers.core.dense.Dense at 0x1d043f973a0>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Also note that the Sequential constructor accepts a name argument, just like any layer or model in Keras. \n",
    "# This is useful to annotate TensorBoard graphs with semantically meaningful names.\n",
    "\n",
    "\n",
    "model = keras.Sequential(name=\"my_sequential\")\n",
    "model.add(keras.layers.Dense(2, activation=\"relu\", name=\"layer1\"))\n",
    "model.add(keras.layers.Dense(3, activation=\"relu\", name=\"layer2\"))\n",
    "model.add(keras.layers.Dense(4, name=\"layer3\"))\n",
    "model.layers\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specifying the input shape in Advance\n",
    "- Generally, all layers in Keras need to know the shape of their inputs in order to be able to create their weights. \n",
    "- So when you create a layer like this, initially, it has no weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = keras.layers.Dense(3)\n",
    "layer.weights  # Empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_6/kernel:0' shape=(4, 3) dtype=float32, numpy=\n",
       " array([[-0.37210792, -0.1146307 , -0.22423726],\n",
       "        [-0.2684635 ,  0.16397238, -0.3094741 ],\n",
       "        [-0.7576456 , -0.6382345 ,  0.7912996 ],\n",
       "        [-0.6900034 ,  0.46272528, -0.28667063]], dtype=float32)>,\n",
       " <tf.Variable 'dense_6/bias:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It creates its weights the first time it is called on an input, \n",
    "# since the shape of the weights depends on the shape of the inputs:\n",
    "# Call layer on a test input\n",
    "x = tf.ones((1, 4))\n",
    "y = layer(x)\n",
    "layer.weights  # Now it has weights, of shape (4, 3) and (3,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of weights after calling the model: 6\n"
     ]
    }
   ],
   "source": [
    "# Naturally, this also applies to Sequential models. \n",
    "# When you instantiate a Sequential model without an input shape, it isn't \"built\": it has no weights (and calling model.weights results in an error stating just this).\n",
    "# The weights are created when the model first sees some input data:\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(2, activation=\"relu\"),\n",
    "        keras.layers.Dense(3, activation=\"relu\"),\n",
    "        keras.layers.Dense(4),\n",
    "    ]\n",
    ")  # No weights at this stage!\n",
    "\n",
    "# At this point, you can't do this:\n",
    "# model.weights\n",
    "\n",
    "# You also can't do this:\n",
    "# model.summary()\n",
    "\n",
    "# Call the model on a test input\n",
    "x = tf.ones((1, 4))\n",
    "y = model(x)\n",
    "print(\"Number of weights after calling the model:\", len(model.weights))  # 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_7 (Dense)             (1, 2)                    10        \n",
      "                                                                 \n",
      " dense_8 (Dense)             (1, 3)                    9         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (1, 4)                    16        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 35\n",
      "Trainable params: 35\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Once a model is \"built\", you can call its summary() method to display its contents:\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 2)                 10        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10\n",
      "Trainable params: 10\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# However, it can be very useful when building a Sequential model incrementally to be able to display the summary of the model so far, including the current output shape. \n",
    "# In this case, you should start your model by passing an Input object to your model, so that it knows its input shape from the start:\n",
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(4,)))\n",
    "model.add(keras.layers.Dense(2, activation=\"relu\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.core.dense.Dense at 0x1d044087610>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that the Input object is not displayed as part of model.layers, since it isn't a layer:\n",
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 2)                 10        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10\n",
      "Trainable params: 10\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# A simple alternative is to just pass an input_shape argument to your first layer:\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(2, activation=\"relu\", input_shape=(4,)))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Models built with a predefined input shape like this always have weights (even before seeing any data) and always have a defined output shape.\n",
    "\n",
    "# In general, it's a recommended best practice to always specify the input shape of a Sequential model in advance if you know what it is."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A common debugging workflow: add() + summary()\n",
    "When building a new Sequential architecture, it's useful to incrementally stack layers with add() and frequently print model summaries. For instance, this enables you to monitor how a stack of Conv2D and MaxPooling2D layers is downsampling image feature maps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 123, 123, 32)      2432      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 121, 121, 32)      9248      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 40, 40, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,680\n",
      "Trainable params: 11,680\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 123, 123, 32)      2432      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 121, 121, 32)      9248      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 40, 40, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 38, 38, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 36, 36, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 12, 12, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 10, 10, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 8, 8, 32)          9248      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 4, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 48,672\n",
      "Trainable params: 48,672\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(250, 250, 3)))  # 250x250 RGB images\n",
    "model.add(keras.layers.Conv2D(32, 5, strides=2, activation=\"relu\"))\n",
    "model.add(keras.layers.Conv2D(32, 3, activation=\"relu\"))\n",
    "model.add(keras.layers.MaxPooling2D(3))\n",
    "\n",
    "# Can you guess what the current output shape is at this point? Probably not.\n",
    "# Let's just print it:\n",
    "model.summary()\n",
    "\n",
    "# The answer was: (40, 40, 32), so we can keep downsampling...\n",
    "\n",
    "model.add(keras.layers.Conv2D(32, 3, activation=\"relu\"))\n",
    "model.add(keras.layers.Conv2D(32, 3, activation=\"relu\"))\n",
    "model.add(keras.layers.MaxPooling2D(3))\n",
    "model.add(keras.layers.Conv2D(32, 3, activation=\"relu\"))\n",
    "model.add(keras.layers.Conv2D(32, 3, activation=\"relu\"))\n",
    "model.add(keras.layers.MaxPooling2D(2))\n",
    "\n",
    "# And now?\n",
    "model.summary()\n",
    "\n",
    "# Now that we have 4x4 feature maps, time to apply global max pooling.\n",
    "model.add(keras.layers.GlobalMaxPooling2D())\n",
    "\n",
    "# Finally, we add a classification layer.\n",
    "model.add(keras.layers.Dense(10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction with Sequential Models\n",
    "Once a Sequential model has been built, it behaves like a Functional API model. This means that every layer has an input and output attribute. These attributes can be used to do neat things, like quickly creating a model that extracts the outputs of all intermediate layers in a Sequential model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_model = keras.Sequential(\n",
    "    [\n",
    "    keras.Input(shape=(250, 250, 3)),\n",
    "    keras.layers.Conv2D(32, 5, strides=2, activation=\"relu\"),\n",
    "    keras.layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "    keras.layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "    ]\n",
    ")\n",
    "feature_extractor = keras.Model(\n",
    "    inputs=initial_model.inputs,\n",
    "    outputs=[layer.output for layer in initial_model.layers]\n",
    ")\n",
    "# Call feature extractor on test input.\n",
    "x = tf.ones((1, 250, 250, 3))\n",
    "features = feature_extractor(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's a similar example that only extract features from one layer:\n",
    "initial_model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(250, 250, 3)),\n",
    "        keras.layers.Conv2D(32, 5, strides=2, activation=\"relu\"),\n",
    "        keras.layers.Conv2D(32, 3, activation=\"relu\", name=\"my_intermediate_layer\"),\n",
    "        keras.layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "    ]\n",
    ")\n",
    "feature_extractor = keras.Model(\n",
    "    inputs=initial_model.inputs,\n",
    "    outputs=initial_model.get_layer(name=\"my_intermediate_layer\").output,\n",
    ")\n",
    "# Call feature extractor on test input.\n",
    "x = tf.ones((1, 250, 250, 3))\n",
    "features = feature_extractor(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer learning with a Sequential model\n",
    "- Transfer learning consists of freezing the bottom layers in a model and only training the top layers. \n",
    "- If you aren't familiar with it, make sure to read our guide to transfer learning.\n",
    "- Here are two common transfer learning blueprint involving Sequential models.\n",
    "- First, let's say that you have a Sequential model, and you want to freeze all layers except the last one. \n",
    "- In this case, you would simply iterate over model.layers and set layer.trainable = False on each layer, except the last one. Like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.Input(shape=(784)),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(10),\n",
    "])\n",
    "\n",
    "# Presumably you would want to first load pre-trained weights.\n",
    "# model.load_weights(...)\n",
    "\n",
    "# Freeze all layers except the last one.\n",
    "for layer in model.layers[:-1]:\n",
    "  layer.trainable = False\n",
    "\n",
    "# Recompile and train (this will only update the weights of the last layer).\n",
    "#model.compile(...)\n",
    "#model.fit(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "83683744/83683744 [==============================] - 20s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Another common blueprint is to use a Sequential model to stack a pre-trained model and \n",
    "# some freshly initialized classification layers. Like this:\n",
    "# Load a convolutional base with pre-trained weights\n",
    "base_model = keras.applications.Xception(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    pooling='avg')\n",
    "\n",
    "# Freeze the base model\n",
    "base_model.trainable = False\n",
    "\n",
    "# Use a Sequential model to add a trainable classifier on top\n",
    "model = keras.Sequential([\n",
    "    base_model,\n",
    "    keras.layers.Dense(1000),\n",
    "])\n",
    "\n",
    "# Compile & train\n",
    "#model.compile(...)\n",
    "#model.fit(...)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_PT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
