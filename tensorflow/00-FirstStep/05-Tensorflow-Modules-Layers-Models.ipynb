{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modules, Layers and Models\n",
    "\n",
    "A model is abstractly:\n",
    "- a function that computes something on tensors (in a forward pass)\n",
    "- Some variable that can be updated in a response to training\n",
    "\n",
    "### Defining Models and Layers in Tensorflow\n",
    "- Most models are made of layers\n",
    "- Layers are functions with a known mathematical structure that can be reused and have trainable variables\n",
    "- in Tensorflow most high-level implementations of layers and models, such as keras and sonnet, or built on the same foundational class **tf.Module**\n",
    "\n",
    "\n",
    "Here's an example of a very simple tf.Module that operates on a scalar tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=30.0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SimpleModule(tf.Module):\n",
    "    def __init__(self, name=None):\n",
    "        super(SimpleModule, self).__init__(name=name)\n",
    "        self.a_variable = tf.Variable(5.0, name=\"train_me\")\n",
    "        self.non_trainable_variable = tf.Variable(5.0,trainable=False, name=\"do_not_train_me\")\n",
    "    def __call__(self,x):\n",
    "        return self.a_variable * x + self.non_trainable_variable\n",
    "    \n",
    "simple_module = SimpleModule(name=\"simple\")\n",
    "simple_module(tf.constant(5.0))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Modules and, by extension, layers are deep-learning terminology for \"objects\": they have internal state, and methods that use that state.\n",
    "- You can set the trainability of variables on and off for any reason, including freezing layers and variables during fine-tuning.\n",
    "- **Note: tf.Module is the base class for both tf.keras.layers.Layer and tf.keras.Model, so everything you come across here also applies in Keras. For historical compatibility reasons Keras layers do not collect variables from modules, so your models should use only modules or only Keras layers. However, the methods shown below for inspecting variables are the same in either case.**\n",
    "- By subclassing tf.Module, any tf.Variable or tf.Module instances assigned to this object's properties are automatically collected. This allows you to save and load variables, and also create collections of tf.Modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable Variables:  (<tf.Variable 'train_me:0' shape=() dtype=float32, numpy=5.0>,)\n",
      "All Variables: (<tf.Variable 'train_me:0' shape=() dtype=float32, numpy=5.0>, <tf.Variable 'do_not_train_me:0' shape=() dtype=float32, numpy=5.0>)\n"
     ]
    }
   ],
   "source": [
    "# All trainable variables\n",
    "print(\"Trainable Variables: \",simple_module.trainable_variables)\n",
    "# Every Varaible\n",
    "print(\"All Variables:\", simple_module.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results: tf.Tensor([[0.4566276 2.815871 ]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# This is an example of a two-layer linear layer model made out of modules.\n",
    "# First lets build a dense (linear) layer\n",
    "class Dense(tf.Module):\n",
    "    def __init__(self, in_features, out_features,name=None):\n",
    "        super(Dense, self).__init__(name=name)\n",
    "        self.w = tf.Variable(tf.random.normal([in_features, out_features]), name='w')\n",
    "        self.b = tf.Variable(tf.zeros([out_features]), name='b')\n",
    "    \n",
    "    def __call__(self,x):\n",
    "        y = tf.matmul(x,self.w) + self.b\n",
    "        return tf.nn.relu(y)\n",
    "\n",
    "#And then the complete model, which makes two layer instances and applies them:\n",
    "\n",
    "class SequentialModule(tf.Module):\n",
    "    def __init__(self, name=None):\n",
    "        super(SequentialModule, self).__init__(name=name)\n",
    "        self.dense1 = Dense(in_features=3, out_features=3)\n",
    "        self.dense2 = Dense(in_features=3, out_features=2)\n",
    "\n",
    "    def __call__(self,x):\n",
    "        x = self.dense1(x)\n",
    "        return self.dense2(x)\n",
    "    \n",
    "# You have made a model!\n",
    "my_model = SequentialModule(name=\"the_model\")\n",
    "# Call it, with random results\n",
    "print(\"Model results:\", my_model(tf.constant([[2.0, 2.0, 2.0]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submodules:  (<__main__.Dense object at 0x000001C305BA62B0>, <__main__.Dense object at 0x000001C306287D90>)\n"
     ]
    }
   ],
   "source": [
    "# tf.Module instances will automatically collect, recursively, any tf.Variable or tf.Module instances assigned to it. \n",
    "# This allows you to manage collections of tf.Modules with a single model instance, and save and load whole models.\n",
    "print(\"Submodules: \", my_model.submodules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'b:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)> \n",
      "\n",
      "<tf.Variable 'w:0' shape=(3, 3) dtype=float32, numpy=\n",
      "array([[-1.8656597 , -0.92340726,  1.6337233 ],\n",
      "       [ 1.3419585 ,  0.32734588, -2.011836  ],\n",
      "       [ 0.6673131 ,  1.4529397 ,  0.6999783 ]], dtype=float32)> \n",
      "\n",
      "<tf.Variable 'b:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)> \n",
      "\n",
      "<tf.Variable 'w:0' shape=(3, 2) dtype=float32, numpy=\n",
      "array([[-1.3162576 , -2.4800007 ],\n",
      "       [ 0.750268  ,  1.9627956 ],\n",
      "       [-0.70074105,  0.255436  ]], dtype=float32)> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for var in my_model.variables:\n",
    "    print(var,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Results:  tf.Tensor([[1.6514297 0.       ]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Waiting to Create variables\n",
    "# By deferring variable creation to the first time the module is called with a specific input shape, \n",
    "# you do not need specify the input size up front.\n",
    "# This flexibility is why TensorFlow layers often only need to specify the shape of their outputs, \n",
    "# such as in tf.keras.layers.Dense, rather than both the input and output size.\n",
    "class FlexibleDenseModule(tf.Module):\n",
    "    def __init__(self, out_features, name=None):\n",
    "        super(FlexibleDenseModule, self).__init__(name=name)\n",
    "        self.is_built = False\n",
    "        self.out_features = out_features\n",
    "    def __call__(self, x):\n",
    "        if not self.is_built:\n",
    "            self.w = tf.Variable(tf.random.normal([x.shape[-1], self.out_features]), name='w')\n",
    "            self.b = tf.zeros([self.out_features], name='b')\n",
    "            self.is_built = True\n",
    "        y = tf.matmul(x,self.w)+self.b\n",
    "        return tf.nn.relu(y)\n",
    "\n",
    "# Lets use this in a model\n",
    "class MySequentialModule(tf.Module):\n",
    "    def __init__(self, name=None):\n",
    "        super(MySequentialModule, self).__init__(name=name)\n",
    "        self.dense1 = FlexibleDenseModule(out_features=3)\n",
    "        self.dense2 = FlexibleDenseModule(out_features=2)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = self.dense1(x)\n",
    "        return self.dense2(x)\n",
    "    \n",
    "my_model = MySequentialModule(name=\"my_model\")\n",
    "print(\"Model Results: \", my_model(tf.constant([[2.0, 2.0, 2.0]])))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Weights\n",
    "\n",
    "- We can save a tf.Module as both a checkpoint and a SavedModel.\n",
    "- Checkpoints are just the weights (that is, the values of the set of variables inside the module and its submodules)\n",
    "- Checkpoints consist of two kinds of files: the data itself and an index file for metadata. \n",
    "- The index file keeps track of what is actually saved and the numbering of checkpoints, while the checkpoint data contains the variable values and their attribute lookup paths.\n",
    "- We can look inside a checkpoint to be sure the whole collection of variables is saved, sorted by the Python object that contains them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my_checkpoint'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chkp_path = \"my_checkpoint\"\n",
    "checkpoint = tf.train.Checkpoint(model=my_model)\n",
    "checkpoint.write(chkp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_checkpoint.data-00000-of-00001\n",
      "my_checkpoint.index\n"
     ]
    }
   ],
   "source": [
    "!ls my_checkpoint*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('_CHECKPOINTABLE_OBJECT_GRAPH', []),\n",
       " ('model/dense1/w/.ATTRIBUTES/VARIABLE_VALUE', [3, 3]),\n",
       " ('model/dense2/w/.ATTRIBUTES/VARIABLE_VALUE', [3, 2])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.list_variables(chkp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[1.6514297, 0.       ]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# During distributed (multi-machine) training they can be sharded, which is why they are numbered (e.g., '00000-of-00001'). In this case, though, there is only have one shard.\n",
    "# When you load models back in, you overwrite the values in your Python object.\n",
    "# Note: As checkpoints are at the heart of long training workflows tf.checkpoint.CheckpointManager is a helper class that makes checkpoint management much easier. \n",
    "# Refer to the Training checkpoints guide for more details.\n",
    "new_model = MySequentialModule()\n",
    "new_checkpoint = tf.train.Checkpoint(model=new_model)\n",
    "new_checkpoint.restore(\"my_checkpoint\")\n",
    "\n",
    "# Should be the same result as above\n",
    "new_model(tf.constant([[2.0, 2.0, 2.0]]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Functions\n",
    "- TensorFlow can run models without the original Python objects, as demonstrated by TensorFlow Serving and TensorFlow Lite, even when you download a trained model from TensorFlow Hub.\n",
    "- TensorFlow needs to know how to do the computations described in Python, but without the original code. To do this, you can make a graph, which is described in the Introduction to graphs and functions guide.\n",
    "- This graph contains operations, or ops, that implement the function.\n",
    "- We can define a graph in the model above by adding the @tf.function decorator to indicate that this code should run as a graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySequentialModule(tf.Module):\n",
    "  def __init__(self, name=None):\n",
    "    super().__init__(name=name)\n",
    "\n",
    "    self.dense_1 = Dense(in_features=3, out_features=3)\n",
    "    self.dense_2 = Dense(in_features=3, out_features=2)\n",
    "\n",
    "  @tf.function\n",
    "  def __call__(self, x):\n",
    "    x = self.dense_1(x)\n",
    "    return self.dense_2(x)\n",
    "\n",
    "# You have made a model with a graph!\n",
    "my_model = MySequentialModule(name=\"the_model\")\n",
    "\n",
    "# The module you have made works exactly the same as before. Each unique signature passed into the function creates a separate graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[7.049494 0.      ]], shape=(1, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[7.049494 0.      ]\n",
      "  [7.049494 0.      ]]], shape=(1, 2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(my_model([[2.0, 2.0, 2.0]]))\n",
    "print(my_model([[[2.0, 2.0, 2.0], [2.0, 2.0, 2.0]]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.        3.6446092]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# We can visualize the graph by tracing it within a TensorBoard summary.\n",
    "\n",
    "# Set up Logging\n",
    "stamp = datetime.now().date()\n",
    "logdir = \"logs/func/%s\" % stamp\n",
    "writer = tf.summary.create_file_writer(logdir)\n",
    "# Create a new model to get a fresh trace\n",
    "# Otherwise the summary will not see the graph\n",
    "new_mode = MySequentialModule()\n",
    "# bracket the function call with tf.summary.trace_on() and tf.summary.trace_export()\n",
    "tf.summary.trace_on(graph=True)\n",
    "tf.profiler.experimental.start(logdir)\n",
    "# Call only one tf.function when tracing\n",
    "z = print(new_mode(tf.constant([[2.0, 2.0, 2.0]])))\n",
    "with writer.as_default():\n",
    "    tf.summary.trace_export(name=\"my_func_trace\", step=0, profiler_outdir=logdir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-a396723baa48e21e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-a396723baa48e21e\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Launch TensorBoard to view the resulting trace:\n",
    "#docs_infra: no_execute\n",
    "%tensorboard --logdir logs/func"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a SavedModel\n",
    "The recommended way of sharing completely trained models is to use SavedModel. SavedModel contains both a collection of functions and a collection of weights.\n",
    "\n",
    "You can save the model you have just trained as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: the_saved_model\\assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(my_model, \"the_saved_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 16\n",
      "drwxr-xr-x 1 F85SJ00 1049089     0 Mar  1 12:06 assets\n",
      "-rw-r--r-- 1 F85SJ00 1049089 14315 Mar  1 12:06 saved_model.pb\n",
      "drwxr-xr-x 1 F85SJ00 1049089     0 Mar  1 12:06 variables\n"
     ]
    }
   ],
   "source": [
    "# Inspect the SavedModel in the directory\n",
    "!ls -l the_saved_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 2\n",
      "-rw-r--r-- 1 F85SJ00 1049089 490 Mar  1 12:06 variables.data-00000-of-00001\n",
      "-rw-r--r-- 1 F85SJ00 1049089 356 Mar  1 12:06 variables.index\n"
     ]
    }
   ],
   "source": [
    "# The variables/ directory contains a checkpoint of the variables\n",
    "!ls -l the_saved_model/variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The saved_model.pb file is a protocol buffer describing the functional tf.Graph.\n",
    "# Models and layers can be loaded from this representation without actually making an instance of the class that created it. \n",
    "# This is desired in situations where you do not have (or want) a Python interpreter, such as serving at scale or on an edge device, \n",
    "# or in situations where the original Python code is not available or practical to use.\n",
    "# You can load the model as new object:\n",
    "new_model = tf.saved_model.load(\"the_saved_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new_model created from loading a saved model, is an internal Tensorflow user object without any of the class knowledge. It is not of type SequentialModule\n",
    "isinstance(new_model, SequentialModule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[7.049494 0.      ]], shape=(1, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[7.049494 0.      ]\n",
      "  [7.049494 0.      ]]], shape=(1, 2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# This new model works on the already-defined input signatures. You can't add more signatures to a model restored like this.\n",
    "print(my_model([[2.0, 2.0, 2.0]]))\n",
    "print(my_model([[[2.0, 2.0, 2.0], [2.0, 2.0, 2.0]]]))\n",
    "# Thus, using SavedModel, you are able to save TensorFlow weights and graphs using tf.Module, and then load them again."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_PT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f0f48898c4b18233cc76a2987cd88405e29ffeb628d5e439f4035f1d0e31c47a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
